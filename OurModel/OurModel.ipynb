{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Xbq725lb2rj","executionInfo":{"status":"ok","timestamp":1734291511839,"user_tz":360,"elapsed":20512,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}},"outputId":"0adff293-1575-4e12-943b-8d5735676206"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# this cell can be modified if your upload location differs"],"metadata":{"id":"jbLbRl0TcV5y","executionInfo":{"status":"ok","timestamp":1734285292279,"user_tz":360,"elapsed":389,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/ELEC576_Team4_Final_Project/OurModel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcqYFgESb4lc","executionInfo":{"status":"ok","timestamp":1734291511840,"user_tz":360,"elapsed":6,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}},"outputId":"f451b1ec-fa31-4acb-ea94-18a764e09662"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ELEC576_Team4_Final_Project/OurModel\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"P93lOFKutZHu","executionInfo":{"status":"ok","timestamp":1734291690043,"user_tz":360,"elapsed":8771,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from torchvision.utils import save_image\n","from PIL import Image\n","import os\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","\n","class RGBThermalDataset(Dataset):\n","    def __init__(self, rgb_dir, thermal_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            rgb_dir (str): Path to RGB images\n","            thermal_dir (str): Path to thermal images\n","            transform (callable, optional): Optional transform to be applied on images\n","        \"\"\"\n","        self.rgb_dir = rgb_dir\n","        self.thermal_dir = thermal_dir\n","        self.transform = transform\n","        self.image_files = os.listdir(rgb_dir)\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.image_files[idx]  # \"<name>_color.jpg\"\n","        base_name = img_name.replace('_color.jpg', '')  # \"<name>\"\n","        rgb_path = os.path.join(self.rgb_dir, img_name)\n","\n","        thermal_name = base_name.replace('_color.png', '.jpg')\n","        thermal_path = os.path.join(self.thermal_dir, thermal_name)\n","\n","        rgb_image = Image.open(rgb_path)\n","        thermal_image = Image.open(thermal_path)\n","\n","        # Apply transformations if they are provided\n","        if self.transform:\n","            rgb_image = self.transform(rgb_image)\n","            thermal_image = self.transform(thermal_image)\n","\n","        return rgb_image, thermal_image\n","\n","class PerceptualLoss(nn.Module):\n","    def __init__(self):\n","        super(PerceptualLoss, self).__init__()\n","        vgg = models.vgg16(pretrained=True).features[:23]\n","        self.features = nn.Sequential(*list(vgg.children()))\n","        self.features.eval()\n","\n","        # Freeze parameters\n","        for param in self.features.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, x, y):\n","        # Convert single channel to 3 channels for VGG\n","        if x.size(1) == 1:\n","            x = x.repeat(1, 3, 1, 1)\n","        if y.size(1) == 1:\n","            y = y.repeat(1, 3, 1, 1)\n","\n","        x_features = self.features(x)\n","        y_features = self.features(y)\n","        return nn.functional.mse_loss(x_features, y_features)\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(channels)\n","\n","    def forward(self, x):\n","        residual = x\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x += residual\n","        x = self.relu(x)\n","        return x\n","\n","class RGBToThermalNet(nn.Module):\n","    def __init__(self):\n","        super(RGBToThermalNet, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            ResidualBlock(64),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            ResidualBlock(128),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            ResidualBlock(256),\n","        )\n","\n","        # Decoder with skip connections\n","        self.decoder_conv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.decoder_res1 = ResidualBlock(128)\n","        self.decoder_conv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.decoder_res2 = ResidualBlock(64)\n","        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Encoder\n","        x1 = self.encoder[:5](x)  # First stage output\n","        x2 = self.encoder[5:10](x1)  # Second stage output\n","        x3 = self.encoder[10:](x2)  # Final encoder output\n","\n","        # Decoder with skip connections\n","        x = self.decoder_conv1(x3)\n","\n","        # Ensure x2 is the same size as x before adding\n","        if x.size() != x2.size():\n","            x2 = nn.functional.interpolate(x2, size=x.shape[2:], mode='bilinear', align_corners=False)\n","\n","        x = x + x2  # Skip connection 1\n","        x = self.decoder_res1(x)\n","\n","        x = self.decoder_conv2(x)\n","\n","        # Ensure x1 is the same size as x before adding\n","        if x.size() != x1.size():\n","            x1 = nn.functional.interpolate(x1, size=x.shape[2:], mode='bilinear', align_corners=False)\n","\n","        x = x + x1  # Skip connection 2\n","        x = self.decoder_res2(x)\n","\n","        x = self.final_conv(x)\n","        return x\n","\n","class Visualizer:\n","    def __init__(self, output_dir='output'):\n","        self.output_dir = output_dir\n","        os.makedirs(output_dir, exist_ok=True)\n","        self.train_losses = []\n","        self.val_losses = []\n","\n","    def save_images(self, epoch, rgb_img, thermal_img, output_img):\n","        # Create a figure with three subplots\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","        # Use tensor_to_image() to convert tensors to correct format\n","        rgb_img = tensor_to_image(rgb_img)\n","        thermal_img = tensor_to_image(thermal_img)\n","        output_img = tensor_to_image(output_img)\n","\n","        axes[0].imshow(rgb_img)\n","        axes[0].set_title('Input RGB')\n","        axes[1].imshow(thermal_img, cmap='inferno')\n","        axes[1].set_title('Ground Truth Thermal')\n","        axes[2].imshow(output_img, cmap='inferno')\n","        axes[2].set_title('Generated Thermal')\n","\n","        plt.savefig(os.path.join(self.output_dir, f'comparison_epoch_{epoch}.png'))\n","        plt.close()\n","\n","    def update_loss_plot(self, train_loss, val_loss):\n","        self.train_losses.append(train_loss)\n","        self.val_losses.append(val_loss)\n","\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(self.train_losses, label='Training Loss')\n","        plt.plot(self.val_losses, label='Validation Loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.savefig(os.path.join(self.output_dir, 'loss_plot.png'))\n","        plt.close()\n","\n","def train_model(model, train_loader, val_loader, num_epochs=50, device='cuda'):\n","    # Initialize losses\n","    mse_criterion = nn.MSELoss()\n","    perceptual_criterion = PerceptualLoss().to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n","\n","    # Initialize visualizer\n","    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    visualizer = Visualizer(output_dir=f'output_{timestamp}')\n","\n","    model = model.to(device)\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        train_loss = 0.0\n","        for i, (rgb_imgs, thermal_imgs) in enumerate(train_loader):\n","            rgb_imgs, thermal_imgs = rgb_imgs.to(device), thermal_imgs.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(rgb_imgs)\n","\n","            # Combine MSE and perceptual loss\n","            mse_loss = mse_criterion(outputs, thermal_imgs)\n","            perceptual_loss = perceptual_criterion(outputs, thermal_imgs)\n","            loss = mse_loss + 0.1 * perceptual_loss\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            '''\n","            # Save example images periodically\n","            if i == 0:  # Save first batch of each epoch\n","                visualizer.save_images(epoch,\n","                                    rgb_imgs[0],\n","                                    thermal_imgs[0],\n","                                    outputs[0])\n","            '''\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for rgb_imgs, thermal_imgs in val_loader:\n","                rgb_imgs, thermal_imgs = rgb_imgs.to(device), thermal_imgs.to(device)\n","                outputs = model(rgb_imgs)\n","                mse_loss = mse_criterion(outputs, thermal_imgs)\n","                perceptual_loss = perceptual_criterion(outputs, thermal_imgs)\n","                val_loss += (mse_loss + 0.1 * perceptual_loss).item()\n","\n","        train_loss /= len(train_loader)\n","        val_loss /= len(val_loader)\n","\n","        scheduler.step(val_loss)\n","\n","        visualizer.update_loss_plot(train_loss, val_loss)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}:')\n","        print(f'Training Loss: {train_loss:.4f}')\n","        print(f'Validation Loss: {val_loss:.4f}')\n","        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","        # Save best model\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'best_val_loss': best_val_loss,\n","            }, 'best_version_our_model.pth')\n","\n","def test_model(model_path, test_loader, device='cuda'):\n","    \"\"\"\n","    Test a trained model on a test dataset and compute metrics\n","\n","    Args:\n","        model_path (str): Path to the saved model checkpoint\n","        test_loader (DataLoader): DataLoader for test dataset\n","        device (str): Device to run the model on\n","    \"\"\"\n","    # Load the trained model\n","    model = RGBToThermalNet()\n","    checkpoint = torch.load(model_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    model = model.to(device)\n","    model.eval()\n","\n","    # Initialize metrics\n","    mse_criterion = nn.MSELoss()\n","    total_mse = 0\n","    total_psnr = 0\n","    total_ssim = 0\n","    total_samples = 0\n","\n","    test_output_dir = 'test_results'\n","    os.makedirs(test_output_dir, exist_ok=True)\n","\n","    with torch.no_grad():\n","        for i, (rgb_imgs, thermal_imgs) in enumerate(test_loader):\n","            rgb_imgs, thermal_imgs = rgb_imgs.to(device), thermal_imgs.to(device)\n","            outputs = model(rgb_imgs)\n","\n","            # Calculate MSE\n","            mse = mse_criterion(outputs, thermal_imgs).item()\n","            total_mse += mse * rgb_imgs.size(0)\n","\n","            # Calculate PSNR and SSIM for each image in batch\n","            for j in range(rgb_imgs.size(0)):\n","                pred = outputs[j].cpu().numpy().squeeze()\n","                target = thermal_imgs[j].cpu().numpy().squeeze()\n","\n","                pred = (pred - pred.min()) / (pred.max() - pred.min())\n","                target = (target - target.min()) / (target.max() - target.min())\n","                target = 0.2989 * target[0, :, :] + 0.5870 * target[1, :, :] + 0.1140 * target[2, :, :]\n","\n","                # Calculate metrics\n","                curr_psnr = psnr(target, pred, data_range=1.0)\n","                curr_ssim = ssim(target, pred, data_range=1.0)\n","\n","                total_psnr += curr_psnr\n","                total_ssim += curr_ssim\n","\n","                if i < 100:\n","                    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","                    # Convert images for visualization\n","                    rgb_img = rgb_imgs[j].cpu().numpy().transpose(1, 2, 0)\n","\n","                    axes[0].imshow(rgb_img)\n","                    axes[0].set_title('Input RGB')\n","                    axes[1].imshow(target, cmap='inferno')\n","                    axes[1].set_title('Ground Truth Thermal')\n","                    axes[2].imshow(pred, cmap='inferno')\n","                    axes[2].set_title(f'Generated Thermal\\nPSNR: {curr_psnr:.2f}, SSIM: {curr_ssim:.2f}')\n","\n","                    plt.savefig(os.path.join(test_output_dir, f'test_sample_{i}_{j}.png'))\n","                    plt.close()\n","\n","            total_samples += rgb_imgs.size(0)\n","\n","            if (i + 1) % 10 == 0:\n","                print(f'Processed {i+1}/{len(test_loader)} batches')\n","\n","    # Calculate average metrics\n","    avg_mse = total_mse / total_samples\n","    avg_psnr = total_psnr / total_samples\n","    avg_ssim = total_ssim / total_samples\n","\n","    # Save metrics to file\n","    metrics = {\n","        'MSE': avg_mse,\n","        'PSNR': avg_psnr,\n","        'SSIM': avg_ssim\n","    }\n","\n","    with open(os.path.join(test_output_dir, 'test_metrics.txt'), 'w') as f:\n","        f.write('Test Metrics:\\n')\n","        f.write(f'Average MSE: {avg_mse:.4f}\\n')\n","        f.write(f'Average PSNR: {avg_psnr:.2f} dB\\n')\n","        f.write(f'Average SSIM: {avg_ssim:.4f}\\n')\n","\n","    print('\\nTest Results:')\n","    print(f'Average MSE: {avg_mse:.4f}')\n","    print(f'Average PSNR: {avg_psnr:.2f} dB')\n","    print(f'Average SSIM: {avg_ssim:.4f}')\n","\n","    return metrics\n","def tensor_to_image(tensor):\n","    \"\"\"\n","    Convert a PyTorch tensor to a numpy array suitable for image display\n","\n","    Args:\n","    tensor (torch.Tensor): Input tensor, expected shapes:\n","        - (C, H, W) for color images\n","        - (H, W) for grayscale images\n","\n","    Returns:\n","    numpy.ndarray: Image array ready for plt.imshow()\n","    \"\"\"\n","    # If tensor is on GPU, move to CPU\n","    if tensor.is_cuda:\n","        tensor = tensor.cpu()\n","\n","    # Normalize tensor if values are not in [0, 1]\n","    if tensor.min() < 0 or tensor.max() > 1:\n","        tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n","\n","    # Handle different tensor shapes\n","    if tensor.dim() == 3:\n","        # Check for (C, H, W) vs (H, W, C)\n","        if tensor.size(0) in [1, 3, 4]:  # Channels first\n","            tensor = tensor.permute(1, 2, 0)\n","\n","        # Squeeze single-channel images\n","        if tensor.size(2) == 1:\n","            tensor = tensor.squeeze(2)\n","\n","    # Convert to numpy\n","    tensor.detach().numpy()\n","\n","    return tensor\n","\n","def display_image(tensor, title=None, cmap=None):\n","    \"\"\"\n","    Display a PyTorch tensor as an image\n","\n","    Args:\n","    tensor (torch.Tensor): Input tensor\n","    title (str, optional): Title for the image\n","    cmap (str, optional): Colormap to use\n","    \"\"\"\n","    plt.figure(figsize=(10, 6))\n","\n","    if cmap is None:\n","        cmap = 'viridis' if tensor.dim() == 2 or (tensor.dim() == 3 and tensor.size(2) == 1) else None\n","\n","    plt.imshow(tensor_to_image(tensor), cmap=cmap)\n","\n","    if title:\n","        plt.title(title)\n","\n","    plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cUMEP0nOyWd2","executionInfo":{"status":"ok","timestamp":1734291690043,"user_tz":360,"elapsed":3,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}}},"outputs":[],"source":["transform = transforms.Compose([\n","        transforms.Resize((288, 384)),\n","        transforms.ToTensor(),\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4Stx-m1wqRD"},"outputs":[],"source":["# Training\n","# Create datasets\n","train_dataset = RGBThermalDataset(\n","    rgb_dir='../dataset/paired/train/vis',\n","    thermal_dir='../dataset/paired/train/ir',\n","    transform=transform\n",")\n","\n","val_dataset = RGBThermalDataset(\n","    rgb_dir='../dataset/paired/train/vis',\n","    thermal_dir='../dataset/paired/train/ir',\n","    transform=transform\n",")\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=14, shuffle=False, num_workers=2)\n","\n","# Initialize model\n","model = RGBToThermalNet()\n","\n","# Train model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_model(model, train_loader, val_loader, num_epochs=50, device=device)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OCBHIRAwL7L","outputId":"87f92b62-b091-47b4-fca2-5374f5b52fd1","executionInfo":{"status":"ok","timestamp":1734292241333,"user_tz":360,"elapsed":387874,"user":{"displayName":"Mason Weiss","userId":"14129217420704859113"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting testing phase...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-733a3786f33d>:274: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(model_path)\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([14, 3, 288, 384])) that is different to the input size (torch.Size([14, 1, 288, 384])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Processed 10/19 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([11, 3, 288, 384])) that is different to the input size (torch.Size([11, 1, 288, 384])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Results:\n","Average MSE: 0.0399\n","Average PSNR: 14.49 dB\n","Average SSIM: 0.4723\n","{'MSE': 0.039916919909077676, 'PSNR': 14.490360496065204, 'SSIM': 0.4722972928462446}\n"]}],"source":["# Testing\n","print(\"\\nStarting testing phase...\")\n","\n","test_dataset = RGBThermalDataset(\n","    rgb_dir='../dataset/paired/val/vis',\n","    thermal_dir='../dataset/paired/val/ir',\n","    transform=transform)\n","\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=14,\n","                         shuffle=False,\n","                         num_workers=4)\n","\n","test_metrics = test_model('best_version_our_model_50.pth', test_loader)\n","print(test_metrics)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}